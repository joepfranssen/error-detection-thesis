{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2wfEhvOdKYs"
      },
      "source": [
        "Connect to drive"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sources:\n",
        "https://medium.com/@bedigunjit/simple-guide-to-text-classification-nlp-using-svm-and-naive-bayes-with-python-421db3a72d34\n",
        "https://www.analyticsvidhya.com/blog/2021/01/a-guide-to-the-naive-bayes-algorithm/"
      ],
      "metadata": {
        "id": "BZGfkIs9m_Va"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNSA6jNndLp6",
        "outputId": "37c84531-9652-4035-b776-301904952a04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uh6MrA7RdSbt",
        "outputId": "53f2324d-6c5f-40b4-c9ab-a2d1104d9b0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Applied Data Science/Thesis/Code\n"
          ]
        }
      ],
      "source": [
        "cd '/content/drive/MyDrive/Applied Data Science/Thesis/Code'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBDYxyZ5dWZ4"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_7tOyf7VBLo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import cross_val_score,KFold\n",
        "from sklearn import naive_bayes\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWOnT408VcgD"
      },
      "source": [
        "Load csv files of retracted and non-retracted articles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c01946b5"
      },
      "outputs": [],
      "source": [
        "five_journal_train_test_data_set = pd.read_csv('/content/drive/MyDrive/Applied Data Science/Thesis/Code/Data (CSV)/five_journal_train_test_data_set.csv', encoding=\"utf-8-sig\")\n",
        "two_journal_external_data_set = pd.read_csv('/content/drive/MyDrive/Applied Data Science/Thesis/Code/Data (CSV)/two_journal_external_data_set.csv', encoding=\"utf-8-sig\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classifier: Countvectorizer"
      ],
      "metadata": {
        "id": "FmELrVb0FcnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paper_sections = ['Title + Abstract PP S', 'Main content PP S', 'Discussion / Conclusion PP S', 'References PP S']\n",
        "\n",
        "for section in paper_sections:\n",
        "  print('\\n########### ' + section + \": \\n\")\n",
        "\n",
        "  if five_journal_train_test_data_set[section].isnull().values.any():\n",
        "    nan_values = five_journal_train_test_data_set[five_journal_train_test_data_set[section].isnull()]\n",
        "    five_journal_train_test_data_set = five_journal_train_test_data_set[~five_journal_train_test_data_set.ID.isin(nan_values.ID)]\n",
        "\n",
        "  raw_X = list(five_journal_train_test_data_set[section].values) # the texts --> X\n",
        "  X = []\n",
        "  y = list(five_journal_train_test_data_set.Retracted.values) # the labels we want to predict --> Y\n",
        "\n",
        "  for i in raw_X:\n",
        "    if len(i.split(\" \")) > 420:\n",
        "      head = i.split(\" \")[0:210]\n",
        "      tail = i.split(\" \")[-210:]\n",
        "      headandtail = \" \".join(head) + \" \".join(tail) \n",
        "    else:\n",
        "      headandtail = i\n",
        "    X.append(headandtail)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.34, random_state=1)\n",
        "  X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=1)\n",
        "\n",
        "  le = LabelEncoder()\n",
        "\n",
        "  y_train = le.fit_transform(y_train)\n",
        "  y_test = le.fit_transform(y_test)\n",
        "\n",
        "  Tfidf_vect = TfidfVectorizer()\n",
        "  Tfidf_vect.fit(X)\n",
        "  Train_X_Tfidf = Tfidf_vect.transform(X_train)\n",
        "  Test_X_Tfidf = Tfidf_vect.transform(X_test)\n",
        "\n",
        "  Naive = naive_bayes.MultinomialNB()\n",
        "  Naive.fit(Train_X_Tfidf,y_train)\n",
        "  predictions_NB = Naive.predict(Test_X_Tfidf)\n",
        "\n",
        "  print(classification_report(y_test, predictions_NB))\n",
        "\n",
        "  print(confusion_matrix(y_test, predictions_NB))\n",
        "\n",
        "  print(\"\\n####### NOW RUNNING ON THE EXTERNAL DATA SET #########\\n\")\n",
        "\n",
        "  if two_journal_external_data_set[section].isnull().values.any():\n",
        "    nan_values = two_journal_external_data_set[two_journal_external_data_set[section].isnull()]\n",
        "    two_journal_external_data_set = two_journal_external_data_set[~two_journal_external_data_set.ID.isin(nan_values.ID)]\n",
        "\n",
        "  raw_X = list(two_journal_external_data_set[section].values) # the texts --> X\n",
        "  X = []\n",
        "  y = list(two_journal_external_data_set.Retracted.values) # the labels we want to predict --> Y\n",
        "\n",
        "  for i in raw_X:\n",
        "    if len(i.split(\" \")) > 420:\n",
        "      head = i.split(\" \")[0:210]\n",
        "      tail = i.split(\" \")[-210:]\n",
        "      headandtail = \" \".join(head) + \" \".join(tail) \n",
        "    else:\n",
        "      headandtail = i\n",
        "    X.append(headandtail)\n",
        "\n",
        "  Test_X_Tfidf = Tfidf_vect.transform(X)\n",
        "\n",
        "  predictions_NB = Naive.predict(Test_X_Tfidf)\n",
        "  print(confusion_matrix(y, predictions_NB))\n",
        "\n",
        "  print(classification_report(y, predictions_NB))"
      ],
      "metadata": {
        "id": "eWhv2Dzs5_Ig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8466f7c9-3f85-4a3c-fb79-c8e0e0f25d7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "########### Title + Abstract PP S: \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.82      0.81        34\n",
            "           1       0.78      0.75      0.76        28\n",
            "\n",
            "    accuracy                           0.79        62\n",
            "   macro avg       0.79      0.79      0.79        62\n",
            "weighted avg       0.79      0.79      0.79        62\n",
            "\n",
            "[[28  6]\n",
            " [ 7 21]]\n",
            "\n",
            "####### NOW RUNNING ON THE EXTERNAL DATA SET #########\n",
            "\n",
            "[[ 58  74]\n",
            " [ 11 121]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.44      0.58       132\n",
            "           1       0.62      0.92      0.74       132\n",
            "\n",
            "    accuracy                           0.68       264\n",
            "   macro avg       0.73      0.68      0.66       264\n",
            "weighted avg       0.73      0.68      0.66       264\n",
            "\n",
            "\n",
            "########### Main content PP S: \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.85      0.82        34\n",
            "           1       0.80      0.71      0.75        28\n",
            "\n",
            "    accuracy                           0.79        62\n",
            "   macro avg       0.79      0.78      0.79        62\n",
            "weighted avg       0.79      0.79      0.79        62\n",
            "\n",
            "[[29  5]\n",
            " [ 8 20]]\n",
            "\n",
            "####### NOW RUNNING ON THE EXTERNAL DATA SET #########\n",
            "\n",
            "[[ 55  77]\n",
            " [ 10 122]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.42      0.56       132\n",
            "           1       0.61      0.92      0.74       132\n",
            "\n",
            "    accuracy                           0.67       264\n",
            "   macro avg       0.73      0.67      0.65       264\n",
            "weighted avg       0.73      0.67      0.65       264\n",
            "\n",
            "\n",
            "########### Discussion / Conclusion PP S: \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      1.00      0.80        26\n",
            "           1       1.00      0.64      0.78        36\n",
            "\n",
            "    accuracy                           0.79        62\n",
            "   macro avg       0.83      0.82      0.79        62\n",
            "weighted avg       0.86      0.79      0.79        62\n",
            "\n",
            "[[26  0]\n",
            " [13 23]]\n",
            "\n",
            "####### NOW RUNNING ON THE EXTERNAL DATA SET #########\n",
            "\n",
            "[[ 87  44]\n",
            " [ 24 108]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.66      0.72       131\n",
            "           1       0.71      0.82      0.76       132\n",
            "\n",
            "    accuracy                           0.74       263\n",
            "   macro avg       0.75      0.74      0.74       263\n",
            "weighted avg       0.75      0.74      0.74       263\n",
            "\n",
            "\n",
            "########### References PP S: \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.81      0.67        26\n",
            "           1       0.80      0.56      0.66        36\n",
            "\n",
            "    accuracy                           0.66        62\n",
            "   macro avg       0.68      0.68      0.66        62\n",
            "weighted avg       0.70      0.66      0.66        62\n",
            "\n",
            "[[21  5]\n",
            " [16 20]]\n",
            "\n",
            "####### NOW RUNNING ON THE EXTERNAL DATA SET #########\n",
            "\n",
            "[[66 65]\n",
            " [67 65]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.50      0.50       131\n",
            "           1       0.50      0.49      0.50       132\n",
            "\n",
            "    accuracy                           0.50       263\n",
            "   macro avg       0.50      0.50      0.50       263\n",
            "weighted avg       0.50      0.50      0.50       263\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "V2_Naive_bayes_final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}